calc.utilities.stan.mc = function(model, data, resp_i = NULL) {
data.df = data.frame(domodelmatrix_itemsonly(data[, 1]))
if (designctx$anchors == 0) data.df = data.df[, -1] # without the Intercept
data.model = as.matrix(data.df)
betas = extract(model, pars = c("Beta"))$Beta
nresps = 1:(dim(betas)[3])
if (!is.null(resp_i)) nresps = array(resp_i, dim = c(1))
ndraws = dim(betas)[1]
utilities = array(dim = c(length(nresps), nrow(data.df), ndraws))
for (d in 1:ndraws) {
for (i in 1:length(nresps)) {
utilities[i, , d] = data.model %*% betas[d, , nresps[i]] # turn i and d in betas
}
}
utilities
}
### HIERARCHICAL BAYES
# data must be a data.frame
# resp_i is a respondent's identifier in the model (can be NULL)
# see also calc.utilities.stan.mc
predict.stan.mc = function(model, data, resp_i = NULL) {
utilities = calc.utilities.stan.mc(model, data)
betas = extract(model, pars = c("Beta"))$Beta
nresps = 1:(dim(betas)[3])
if (!is.null(resp_i)) nresps = array(resp_i, dim = c(1))
ndraws = dim(betas)[1]
shares = array(dim = c(length(nresps), nrow(data), ndraws))
for (d in 1:ndraws) {
for (i in 1:length(nresps)) {
shares[i, , d] = (exp(utilities[i, , d])/sum(exp(utilities[i, , d]))) * 100
}
}
shares.agg = apply(shares, 2:3, mean)
r = cbind(data,
"share %" = apply(shares.agg, 1, mean)
# ,
# "5%" = apply(shares.agg, 1, quantile, probs = c(0.05)),
# "95%" = apply(shares.agg, 1, quantile, probs = c(0.95))
)
rownames(r) = c()
r[["share %"]] = as.numeric(round(r[["share %"]], digits = 2))
# r[["5%"]] = as.numeric(round(r[["5%"]], digits = 2))
# r[["95%"]] = as.numeric(round(r[["95%"]], digits = 2))
r
}
### HIERARCHICAL BAYES
# data must be a data.frame
# resp_i is a respondent's identifier in the model
# see also predict.stan.mc and calc.utilities.stan.mc
predict.stan.mc.choice = function(model, data, resp_i) {
shares = predict.stan.mc(model, data, resp_i)
best_choice = worst_choice = rep(0, nrow(data))
best_choice[which.max(shares[["share %"]])] = 1
worst_choice[which.min(shares[["share %"]])] = 1
r = cbind(data, "share %" = shares[["share %"]], best_choice = best_choice, worst_choice = worst_choice)
rownames(r) = c()
r
}
# fullfact_design = combn(designctx$items, designctx$nalternatives)
# ffd_df = fullfact_design[, sample(1:ncol(fullfact_design), 10, replace = FALSE)]
# ffd_df = unlist(lapply(1:ncol(ffd_df), function(c) ffd_df[, c])) # data treba biti jednostavna lista opcija, ostalo će se kreirati
# ffd_df = data.frame(opcije = ffd_df)
# trebalo bi uspoređivati samo kombinacije s brojem opcija jednakim kao što je bilo kod kreiranja modela (nalternatives)
# ali prema ormeu svi to rade bez obzira na broj opcija pa ćemo i mi
#ffd_df = data.frame(opcije = designctx$items)
ffd_df = data.frame(opcije = designctx$items[sample(5)])
# fullfact_covdesign = designctx$fullfact_covdesign
# if (length(designctx$covariates) > 0) {
#   ffd_covdf = fullfact_covdesign[sample(1:nrow(fullfact_covdesign), 10, replace = TRUE), ]
#   ffd_df = cbind(ffd_df, ffd_covdf)
# }
shares.mnl = predict.hier.mnl(m2.hier, data = ffd_df)
shares.hb = predict.hb.mnl(hb.post, data = ffd_df)
shares.stan.mc = predict.stan.mc(stan.mc, data = ffd_df)
shares.stan.mc.lca = predict.stan.mc(stan.mc.lca, data = ffd_df)
shares = shares.hb
shares = shares.stan.mc
shares = shares.stan.mc.lca
#shares
mostsharesindex = which.max(shares[["share %"]])
mostshare = shares[mostsharesindex, ]
t(shares)
holdout_respondents_n = 30
holdout_respondents_q = 3
holdout_respondents = sample(1:max(cbc.df$resp.id), holdout_respondents_n, replace = FALSE)
holdout_questions = sample(1:max(cbc.df$ques), holdout_respondents_q, replace = FALSE)
keep_cols = c("alt")
rgrid = expand.grid(holdout_questions, holdout_respondents)
holdout_true_predicted = matrix(
NA,
nrow = holdout_respondents_n * holdout_respondents_q,
ncol = 6,
dimnames = list(
"respondent/question" = paste(rgrid$Var2, "/", rgrid$Var1, sep = ""),
"choice" = c("true best", "predicted best", "correct best", "true worst", "predicted worst", "correct worst")
)
)
holdout_true_predicted_mnl = holdout_true_predicted_hb = holdout_true_predicted_stan_mc = holdout_true_predicted_stan_mc_lca = holdout_true_predicted
for (i in 1:holdout_respondents_n) { # respondent
for (j in 1:holdout_respondents_q) { # question
ffd_df = cbc.df[(cbc.df$resp.id == holdout_respondents[i]) & (cbc.df$ques == holdout_questions[j]), ]
true_best_choice = which(ffd_df$best_choice == 1)
true_worst_choice = which(ffd_df$worst_choice == 1)
ffd_df = getdfcolumns(ffd_df, cnames = keep_cols)
# predicted = predict.hier.mnl.choice(m2.hier, ffd_df, holdout_respondents[i])
# predicted_best_choice = which(predicted$best_choice == 1)
# predicted_worst_choice = which(predicted$worst_choice == 1)
# holdout_true_predicted_mnl[(i-1)*holdout_respondents_q+j, ] =
#   c(true_best_choice, predicted_best_choice, true_best_choice == predicted_best_choice,
#     true_worst_choice, predicted_worst_choice, true_worst_choice == predicted_worst_choice)
#
predicted = predict.hb.mnl.choice(hb.post, ffd_df, holdout_respondents[i])
predicted_best_choice = which(predicted$best_choice == 1)
predicted_worst_choice = which(predicted$worst_choice == 1)
holdout_true_predicted_hb[(i-1)*holdout_respondents_q+j, ] =
c(true_best_choice, predicted_best_choice, true_best_choice == predicted_best_choice,
true_worst_choice, predicted_worst_choice, true_worst_choice == predicted_worst_choice)
# predicted = predict.stan.mc.choice(stan.mc, ffd_df, holdout_respondents[i])
# predicted_best_choice = which(predicted$best_choice == 1)
# predicted_worst_choice = which(predicted$worst_choice == 1)
# holdout_true_predicted_stan_mc[(i-1)*holdout_respondents_q+j, ] =
#   c(true_best_choice, predicted_best_choice, true_best_choice == predicted_best_choice,
#     true_best_choice, predicted_worst_choice, true_worst_choice == predicted_worst_choice)
#
# predicted = predict.stan.mc.choice(stan.mc.lca, ffd_df, holdout_respondents[i])
# predicted_best_choice = which(predicted$best_choice == 1)
# predicted_worst_choice = which(predicted$worst_choice == 1)
# holdout_true_predicted_stan_mc_lca[(i-1)*holdout_respondents_q+j, ] =
#   c(true_best_choice, predicted_best_choice, true_best_choice == predicted_best_choice,
#     true_best_choice, predicted_worst_choice, true_worst_choice == predicted_worst_choice)
}
}
# sum(holdout_true_predicted_mnl[, "correct best"])/nrow(holdout_true_predicted_mnl)
# sum(holdout_true_predicted_mnl[, "correct worst"])/nrow(holdout_true_predicted_mnl)
# sum(holdout_true_predicted_hb[, "correct best"])/nrow(holdout_true_predicted_hb)
# sum(holdout_true_predicted_hb[, "correct worst"])/nrow(holdout_true_predicted_hb)
# sum(holdout_true_predicted_stan_mc[, "correct best"])/nrow(holdout_true_predicted_stan_mc)
# sum(holdout_true_predicted_stan_mc[, "correct worst"])/nrow(holdout_true_predicted_stan_mc)
# sum(holdout_true_predicted_stan_mc_lca[, "correct best"])/nrow(holdout_true_predicted_stan_mc_lca)
# sum(holdout_true_predicted_stan_mc_lca[, "correct worst"])/nrow(holdout_true_predicted_stan_mc_lca)
#holdout_true_predicted = holdout_true_predicted_mnl
holdout_true_predicted = holdout_true_predicted_hb
#holdout_true_predicted = holdout_true_predicted_stan_mc
#holdout_true_predicted = holdout_true_predicted_stan_mc_lca
holdout_true_predicted[sample(1:nrow(holdout_true_predicted), 20), !(colnames(holdout_true_predicted) %in% c("correct best", "correct worst"))]
#holdout_true_predicted[sample(1:nrow(holdout_true_predicted), 20), ]
total_correct = sum(holdout_true_predicted[, "correct best"]) + sum(holdout_true_predicted[, "correct worst"])
paste("Ukupno točno predviđanja:", round(100*total_correct/(2*nrow(holdout_true_predicted)), digits = 2), "%", sep = "")
head(beta.post.mean)
nrow(beta.post.mean)
designctx$items
head(stan.mc.betas.mean)
head(t(stan.mc.betas.mean))
head(t(stan.mc.lca.betas.mean))
choose(14, 3)
choose(14, 5)
sm.mnl
summary(m2.hier)
#############################################################################################################
### >>> MIXED MNL
library(mlogit)
cov.df = data.frame() # ovo spremamo da bismo kasnije mogli raditi predikciju s istim ovim ispitanicima
# here we build fml1, which will be used to create a model and model matrix for mlogit
if (length(designctx$covariates) == 0) {
fmlstring = paste("choice ~ 0 + ", paste(colnames(mm), collapse = "+")) # all vars have generic coefs
fml1 = as.formula(fmlstring)
} else {
#  ncov.columns = setdiff(colnames(mm), cov.columns)
ncov.columns = items.columns
fmlstring1 = paste("0 +", paste(ncov.columns, collapse = "+")) # all but covariates have generic coefs
fmlstring2 = paste("0 +", paste(cov.columns, collapse = "+")) # covariates will have alternative specific coefs
fmlstring = paste("choice ~", fmlstring1, "|", fmlstring2)
fml1 = mFormula(as.formula(fmlstring)) # ovdje je bitno da bude mFormula tako da se kod model.matrix pozove odgovarajuća funkcija!!! >> TO JE SAMO ZA mlogit, NE ZA choicemodelr!
# fmlstring = paste("choice ~ 0 + ", paste(colnames(mm), collapse = "+")) # all vars have generic coefs
# fml1 = mFormula(as.formula(fmlstring))
# fml1 = as.formula(fmlstring)
repeats = designctx$nquestions * designctx$nalternatives
respondents = max(cbc.df$resp.id)
cov.df = as.data.frame(cbc.df[(0:(respondents-1))*repeats+1, colnames(cbc.df) %in% names(designctx$covariates)])
colnames(cov.df) = names(designctx$covariates)
}
# fml1 = as.formula(paste("choice ~ ", paste(g.columns, collapse = "+"), "| 0 |", paste(ascolumns, collapse = "+")))
# head(model.matrix(fml1, cbc.mlogit), 10)
vars_i = 4:(ncol(cbc.mm)-1) # skip over the first three: resp.id, ques, alt
cbc.mm$resp.ques = paste(cbc.mm$resp.id, ".", cbc.mm$ques, sep = "")
cbc.mlogit = mlogit.data(data = cbc.mm, choice = "choice", shape = "long",
#varying = vars_i,
alt.var = "alt",
#alt.levels = levels(factor(cbc.mm$alt)),
#alt.levels = unique(cbc.mm$alt),
chid.var = "resp.ques",
id.var = "resp.id")
## BUILD AND SAVE MODEL
# Ako imamo covariates, onda model prolazi samo ako se koeficijenti covariates računaju kao alternative specific
# (znači u formuli idu iza | i s 0 +)
m1 = mlogit(fml1, data = cbc.mlogit)
# summary(m1)
m1.rpar = rep("n", length = length(m1$coef)) # 'n' normal, 'l' log-normal, 't' truncated normal, 'u' uniform
names(m1.rpar) = names(m1$coef)
m2.hier = mlogit(fml1, data = cbc.mlogit, panel = TRUE, rpar = m1.rpar, correlation = TRUE)
# summary(m1.hier)
# m2.hier = update(m1.hier, correlation = TRUE)
# summary(m2.hier)
# SAVE/LOAD
m2.hier$cov.df = cov.df
saveRDS(m2.hier, mnlmodelfile)
## LOAD MODEL
if (!is.null(cbc.mm$resp.ques)) cbc.mm$resp.ques = NULL
m2.hier = readRDS(mnlmodelfile)
sm.mnl = summary(m2.hier)$summary.rpar
#print(sm.mnl[, !(colnames(sm.mnl) %in% c("Min.", "Median", "Max."))])
### MIXED MNL <<<
#############################################################################################################
sm.mnl
summary(m2.hier)
cov.mlogit(m2.hier)
calc.utilities.hb(model = hb.post, data = ffd_df, resp_i = 17)
ffd_df_utils = calc.utilities.hb(model = hb.post, data = ffd_df, resp_i = 17)
ffd_df_utils = calc.utilities.hb(model = hb.post, data = ffd_df)
str(ffd_df_utils)
ffd_df_utils = calc.utilities.hb(model = hb.post, data = ffd_df, resp_i = 17)
str(ffd_df)
# trebalo bi uspoređivati samo kombinacije s brojem opcija jednakim kao što je bilo kod kreiranja modela (nalternatives)
# ali prema ormeu svi to rade bez obzira na broj opcija pa ćemo i mi
#ffd_df = data.frame(opcije = designctx$items)
ffd_df = data.frame(opcije = designctx$items[sample(5)])
ffd_df_utils = calc.utilities.hb(model = hb.post, data = ffd_df, resp_i = 17)
300*7.5
?choicemodelr
str(hb.post)
str(designctx$items)
resp_coefs
comb_size = 5 # size of the TURF combination that we will test
items_combs = combn(designctx$items, comb_size)
items_combs
items_combs[, 1]
items_combs[, 2]
items_combs[, 3]
items_combs[, 4]
ncol(items_combs)
ncol(items_combscbc.df$resp.id
)
cbc.df$resp.id
unique(cbc.df$resp.id)
i = 1
r = 1
calc.utilities.mnl(model = m2.hier, data = items_combs[, i], resp_i = r)
str(items_combs[, i])
data.frame(items_combs[, i])
data.frame(opcije = items_combs[, i])
str(data.frame(opcije = items_combs[, i]))
calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
debugSource('C:/OnlineSync/Mega/R/work/maxdiff/test/temp.R', encoding = 'UTF-8')
utilities
debugSource('C:/OnlineSync/Mega/R/work/maxdiff/test/temp.R', encoding = 'UTF-8')
utilities
debugSource('C:/OnlineSync/Mega/R/work/maxdiff/test/temp.R', encoding = 'UTF-8')
# model must contain cov.df (can be empty)
# data must be a data.frame with the items alternatives in the 1st column
# if resp_i is not NULL, calculate utilities for only 1 respondent
# if cov.df is not empty, take the covariates from it for the respondent with index resp_i
# if resp_i is NULL, calculate average for either nrow(cov.df) respondents if cov.df is not empty or for 1000 respondents (without any covariates)
# returns matrix of utilities, nresp x nrow(data)
calc.utilities.mnl = function(model, data, resp_i = NULL) {
# alt is the alternatives column, must be prepared to meet mlogit conditions
# resp_cov is a row of respondent's covariates (must be a data.frame, can be empty)
# returns matrix-row of utilities, 1 x nrow(data)
calc.utilities.mnl_resp = function(model, data, alt, resp_cov) {
coef.Sigma = cov.mlogit(model)
coef.mu = model$coef[1:dim(coef.Sigma)[1]]
draw_i = mvrnorm(1, coef.mu, coef.Sigma)
nalts = designctx$nalternatives
if (nrow(resp_cov) > 0) {
# add covariates to the data frame
# n_d = ncol(data)
# data = cbind(data, resp_cov[rep(1, nrow(data)), ])
# colnames(data)[(n_d+1):ncol(data)] = colnames(resp_cov)
resp_cov = getdfcolumns(resp_cov[rep(1, nrow(data)), ], cnames = colnames(resp_cov))
ffd_mm = domodelmatrix_itemscovs(data[, 1], resp_cov)
} else {
ffd_mm = domodelmatrix_itemsonly(data[, 1])
}
if (designctx$anchors == 0) ffd_mm = ffd_mm[, -1] # without the Intercept
ffd_mm$alt = alt
ffd_mm$choice = rep(1, nrow(ffd_mm))
ffd.mlogit = mlogit.data(data = ffd_mm, choice = "choice", shape = "long", varying = 1:(ncol(ffd_mm)-2), alt.var = "alt", alt.levels = levels(ffd_mm$alt))
data.model = model.matrix(model$formula, data = ffd.mlogit)
utilities = data.model %*% draw_i
t(utilities) # to get a row vector
}
# returns matrix of utilities, 1000 x nrow(data)
calc.utilities.mnl_resps_without_cov = function(model, data, alt) {
nresp = 1000
utilities = matrix(NA, nrow = nresp, ncol = nrow(data))
for (i in 1:nresp) {
utilities[i, ] = calc.utilities.mnl_resp(model, data, alt, data.frame())
}
utilities
}
# returns matrix of utilities, nrow(resp_cov) x nrow(data)
calc.utilities.mnl_resps_with_cov = function(model, data, alt, resp_cov) {
nresp = nrow(resp_cov)
utilities = matrix(NA, nrow = nresp, ncol = nrow(data))
for (i in 1:nresp) {
utilities[i, ] = calc.utilities.mnl_resp(model, data, alt, getdfcolumns(resp_cov[i, ], cnames = colnames(resp_cov)))
}
utilities
}
# ovo moramo napraviti zbog uvjeta u mlogit.data (broj redaka mora biti višekratnik od broja alternativa)
# ako broj redaka nije višekratnik, onda ćemo (bez utjecaja na izračun utilitya) iskopirati na kraj data
# još n_add redaka (1. redak), a kasnije ćemo to maknuti
n_add = 0
altlevels = as.numeric(levels(attributes(model$model$choice)$index$alt))
# ovo moramo napraviti iz istog razloga kao gore, s time da alt moramo izvući iz modela
# ne možemo staviti bezveze jer ako npr. koristimo covariates, onda su njihovi koeficijenti vezani
# za alternativu (alternative specific) pa ovise o alternativi i alternativa mora biti definirana
# kako je ovo samo za predikciju, postavljamo alt za sve podatke na istu vrijednost (nadamo se da će
# relativni omjeri i dalje ostati isti)
n_alts = length(altlevels)
n_df = nrow(data)
if ((n_df %% n_alts) > 0) {
n_add = ceiling(n_df/n_alts)*n_alts - n_df
data.add = getdfcolumns(data[rep(1, n_add), ], cnames = colnames(data))
data = rbind(data, data.add)
}
alt = factor(rep(altlevels, nrow(data)/n_alts), levels = altlevels)
if (is.null(resp_i)) {
if (nrow(model$cov.df) > 0) {
utilities = calc.utilities.mnl_resps_with_cov(model, data, alt, model$cov.df)
} else {
utilities = calc.utilities.mnl_resps_without_cov(model, data, alt)
}
} else {
if (nrow(model$cov.df) > 0) {
utilities = calc.utilities.mnl_resp(model, data, alt, getdfcolumns(model$cov.df[resp_i, ], cnames = colnames(model$cov.df)))
} else {
utilities = calc.utilities.mnl_resp(model, data, alt, data.frame())
}
}
if (n_add > 0) utilities = utilities[, -((ncol(utilities)-n_add+1):ncol(utilities))]
utilities
}
debugSource('C:/OnlineSync/Mega/R/work/maxdiff/test/temp.R', encoding = 'UTF-8')
utilities
utilities
utilities
items_combs
items_combs[, 1]
combs_r_f = array(0, dim = c(ncol(items_combs), 2))
reached = c(TRUE, FALSE, TRUE, TRUE, FALSE)
sum(reached)
comb_size = 5 # size of the TURF combination that we will test
items_combs = combn(designctx$items, comb_size)
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
for (i in 1:ncol(items_combs)) {
for (r in unique(cbc.df$resp.id)) {
ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = any(reached)
combs_r_f[i, 2] = sum(reached)
}
}
100%%10
101%%10
104%%10
comb_size = 5 # size of the TURF combination that we will test
items_combs = combn(designctx$items, comb_size)
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
for (i in 1:ncol(items_combs)) {
for (r in unique(cbc.df$resp.id)) {
ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = any(reached)
combs_r_f[i, 2] = sum(reached)
}
if ((i %% 10) == 0) print(i)
}
for (i in 1:ncol(items_combs)) {
print(i)
for (r in unique(cbc.df$resp.id)) {
ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = any(reached)
combs_r_f[i, 2] = sum(reached)
}
if ((i %% 10) == 0) print(i)
}
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
for (i in 1:ncol(items_combs)) {
print(i)
for (r in unique(cbc.df$resp.id)) {
#    ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
ir_utils = calc.utilities.hb(model = hb.post, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = any(reached)
combs_r_f[i, 2] = sum(reached)
}
}
comb_size = 3 # size of the TURF combination that we will test
items_combs = combn(designctx$items, comb_size)
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
for (i in 1:ncol(items_combs)) {
print(i)
for (r in unique(cbc.df$resp.id)) {
#    ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
ir_utils = calc.utilities.hb(model = hb.post, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = any(reached)
combs_r_f[i, 2] = sum(reached)
}
}
comb_size = 3 # size of the TURF combination that we will test
items_combs = combn(designctx$items, comb_size)
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
combs_r_f[1, 1]
combs_r_f[1, 2]
combs_r_f[1, 3]
reached
reached = c(TRUE, FALSE, TRUE, TRUE, FALSE)
any(reached)
as.numeric(any(reached))
as.numeric(sum(reached))
###  >>>
items_combs = combn(designctx$items, comb_size)
combs_r_f = array(0, dim = c(ncol(items_combs), 2)) # 1st column is reach, 2nd is frequency
for (i in 1:ncol(items_combs)) {
for (r in unique(cbc.df$resp.id)) {
#    ir_utils = calc.utilities.mnl(model = m2.hier, data = data.frame(opcije = items_combs[, i]), resp_i = r)
ir_utils = calc.utilities.hb(model = hb.post, data = data.frame(opcije = items_combs[, i]), resp_i = r)
probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
reached = sapply(probs_reach, function(prob_reach) {
sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
})
combs_r_f[i, 1] = combs_r_f[i, 1] + as.numeric(any(reached))
combs_r_f[i, 2] = combs_r_f[i, 2] + as.numeric(sum(reached))
}
if ((i %% 10) == 0) print(i)
}
###  <<<
#############################################################################################################
combs_r_f[1, ]
combs_r_f[2, ]
combs_r_f[3, ]
combs_r_f[4, ]
combs_r_f[5, ]
saveRDS(combs_r_f, "turf.RDS")
turffile = paste(cbcid, "_turf.RDS", sep = "")
#     ir_utils = calc.utilities.hb(model = hb.post, data = data.frame(opcije = items_combs[, i]), resp_i = r)
#     probs_reach = exp(ir_utils)/(sum(exp(ir_utils))+1) # ovo je ok ako imamo anchor, provjeriti još da li je ok ako ga nemamo
#     reached = sapply(probs_reach, function(prob_reach) {
#       sample(c(TRUE, FALSE), 1, replace = FALSE, prob = c(prob_reach, 1-prob_reach))
#     })
#     combs_r_f[i, 1] = combs_r_f[i, 1] + as.numeric(any(reached))
#     combs_r_f[i, 2] = combs_r_f[i, 2] + as.numeric(sum(reached))
#   }
# #  if ((i %% 10) == 0) print(i)
# }
saveRDS(combs_r_f, turffile)
combs_r_f = readRDS(turffile)
combs_r_f[order(combs_r_f[, 1]), ]
combs_r_f[order(combs_r_f[, 1], decreasing = TRUE), ]
combs_r_f = combs_r_f[order(combs_r_f[, 1], decreasing = TRUE), ]
head(combs_r_f)
combs_r_f = readRDS(turffile)
rownames(combs_r_f)
head(combs_r_f)
items_combs[, 1]
rownames(combs_r_f) = 1:ncol(items_combs)
head(combs_r_f)
rownames(combs_r_f) =
combs_r_f = combs_r_f[order(combs_r_f[, 1], decreasing = TRUE), ]
items_combs[, 1:ncol(items_combs)]
items_combs[, 1]
items_combs[, 2]
items_combs[, 3]
as.character(items_combs[, 3])
paste(as.character(items_combs[, 3]), collapse = ",")
paste(as.character(items_combs[, 3]), collapse = ", ")
combs_r_f = readRDS(turffile)
rownames(combs_r_f) = sapply(1:ncol(items_combs), function(i) paste(as.character(items_combs[, i]), collapse = ", "))
head(combs_r_f)
colnames(combs_r_f) = c("reach", "frequency")
head(combs_r_f)
combs_r_f[order(combs_r_f[, 1], decreasing = TRUE), ]
combs_r_f = combs_r_f[order(combs_r_f[, 1], decreasing = TRUE), ]
head(combs_r_f)
combs_r_f[1, ]
combs_r_f[, 1]
rownames(combs_r_f[1, ])
rownames(combs_r_f)[1]
rownames(combs_r_f)[1:3]
combs_r_f[1, 1]
combs_r_f[1, 2]
unique(cbc.df$resp.id)
length(unique(cbc.df$resp.id))
round(combs_r_f[1, 1]/length(unique(cbc.df$resp.id)), 2)
round(combs_r_f[1, 1]/length(unique(cbc.df$resp.id)), 2)*100
