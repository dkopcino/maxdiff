nalts = designctx$nalternatives
if (length(designctx$covariates) > 0) {
covs = getdfcolumns(df = cbc.df.sf, cnames = names(designctx$covariates))
sf.mm = domodelmatrix_itemscovs_bwencode(cbc.df.sf$alt, covs, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = attr(sf.mm, "cov.columns")
} else {
covs = data.frame() # da li je ovo uopće potrebno?
sf.mm = domodelmatrix_itemsonly_bwencode(cbc.df.sf$alt, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = c()
}
cbc.mm.sf = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df.sf$resp.id, nalts),
ques = rep(1:(2*max(cbc.df.sf$ques)), each = nalts),
#alt = cbc.df$alt,
alt = rep(1:nalts, nrow(sf.mm)/nalts),
sf.mm,
choice = bw_encode_data(cbc.df.sf$best_choice, cbc.df.sf$worst_choice, nalts)))
if (designctx$anchors > 0) {
anchorcolnames = getanchorcolnames(designctx$anchors)
anchorcols = cbc.df.sf[, colnames(cbc.df.sf) %in% anchorcolnames]
best_choices = cbc.df[cbc.df$best_choice == 1, ]$alt
worst_choices = cbc.df[cbc.df$worst_choice == 1, ]$alt
anchors = getanchors(designctx$anchors, best_choices, worst_choices)
if (length(designctx$covariates) > 0) {
anch.mm = domodelmatrix_itemscovs(anchors, getdfcolumns(covs[rep(1, length(anchors)), ], cnames = colnames(covs)))
} else {
anch.mm = domodelmatrix_itemsonly(anchors)
}
anch.mm = anch.mm[rep(1:nrow(anch.mm), each = 2), ]
anch.mm[2*(1:(nrow(anch.mm)/2)), items.columns] = 0
anch.choices = rep(t(anchorcols[1, ]), each = 2)
anch.choices[2*(1:(length(anch.choices)/2))-1][anchorcols[1, ] == 2] = 0 # neparni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 1] = 0 # parni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 2] = 1 # parni
anch.mm.sf = data.frame(cbind(resp.id = rep(resp.id, nrow(anch.mm)),
ques = rep(max(cbc.mm.sf$ques+1):(max(cbc.mm.sf$ques)+length(anchors)), each = 2),
alt = rep(1:2, nrow(anch.mm)/2),
anch.mm,
choice = anch.choices))
cbc.mm.sf = rbind(cbc.mm.sf, anch.mm.sf)
}
cbc.mm = rbind(cbc.mm, cbc.mm.sf)
}
rownames(cbc.mm) = c()
if (designctx$anchors == 0) {
# remove the Intercept column - it is essentially contained in the alt column (Intercept is when all predictors are 0 - that leaves only the alt as the predictor)
# when we use anchors, then the threshold option is the 0 option, and we don't need to remove the Intercept created with modelling
cbc.mm = cbc.mm[, -4] # 1st item column is the 4th column (after resp.id, ques and alt)
items.columns = items.columns[-1]
}
# items.columns = items.columns[-1]
#
# cbc.mm = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df$resp.id, nalts),
#                           ques = rep(rep(1:(2*designctx$nquestions), each = nalts), max(cbc.df$resp.id)),
# #                          alt = cbc.df$alt,
#                           alt = rep(1:nalts, nrow(mm)/nalts),
#                           mm,
#                           choice = bw_encode_data(cbc.df$best_choice, cbc.df$worst_choice, nalts)))
#
# helper za neke situacije, npr. za stan.mc
cbc.mm.clear = cbc.mm[, items.columns]
#############################################################################################################
### >>> MIXED MNL
library(mlogit)
cov.df = data.frame() # ovo spremamo da bismo kasnije mogli raditi predikciju s istim ovim ispitanicima
# here we build fml1, which will be used to create a model and model matrix for mlogit
if (length(designctx$covariates) == 0) {
fmlstring = paste("choice ~ 0 + ", paste(items.columns, collapse = "+")) # all vars have generic coefs
fml1 = as.formula(fmlstring)
} else {
#  ncov.columns = setdiff(colnames(mm), cov.columns)
ncov.columns = items.columns
fmlstring1 = paste("0 +", paste(ncov.columns, collapse = "+")) # all but covariates have generic coefs
fmlstring2 = paste("0 +", paste(cov.columns, collapse = "+")) # covariates will have alternative specific coefs
fmlstring = paste("choice ~", fmlstring1, "|", fmlstring2)
fml1 = mFormula(as.formula(fmlstring)) # ovdje je bitno da bude mFormula tako da se kod model.matrix pozove odgovarajuća funkcija!!! >> TO JE SAMO ZA mlogit, NE ZA choicemodelr!
# fmlstring = paste("choice ~ 0 + ", paste(colnames(mm), collapse = "+")) # all vars have generic coefs
# fml1 = mFormula(as.formula(fmlstring))
# fml1 = as.formula(fmlstring)
repeats = designctx$nquestions * designctx$nalternatives
respondents = max(cbc.df$resp.id)
cov.df = as.data.frame(cbc.df[(0:(respondents-1))*repeats+1, colnames(cbc.df) %in% names(designctx$covariates)])
colnames(cov.df) = names(designctx$covariates)
}
# fml1 = as.formula(paste("choice ~ ", paste(g.columns, collapse = "+"), "| 0 |", paste(ascolumns, collapse = "+")))
# head(model.matrix(fml1, cbc.mlogit), 10)
vars_i = 4:(ncol(cbc.mm)-1) # skip over the first three: resp.id, ques, alt
cbc.mm$resp.ques = paste(cbc.mm$resp.id, ".", cbc.mm$ques, sep = "")
cbc.mlogit = mlogit.data(data = cbc.mm, choice = "choice", shape = "long",
#varying = vars_i,
alt.var = "alt",
#alt.levels = levels(factor(cbc.mm$alt)),
#alt.levels = unique(cbc.mm$alt),
chid.var = "resp.ques",
id.var = "resp.id")
## BUILD AND SAVE MODEL
# Ako imamo covariates, onda model prolazi samo ako se koeficijenti covariates računaju kao alternative specific
# (znači u formuli idu iza | i s 0 +)
m1 = mlogit(fml1, data = cbc.mlogit)
# summary(m1)
m1.rpar = rep("n", length = length(m1$coef)) # 'n' normal, 'l' log-normal, 't' truncated normal, 'u' uniform
names(m1.rpar) = names(m1$coef)
m2.hier = mlogit(fml1, data = cbc.mlogit, panel = TRUE, rpar = m1.rpar, correlation = TRUE)
#############################################################################################################
### >>> HIERARCHICAL BAYES
library(ChoiceModelR)
# # modeliranje
cmr_choice = rep(0, nrow(cbc.mm))
cmr_choice[cbc.mm$alt == 1] = cbc.mm[cbc.mm$choice == 1, "alt"]
cmr.mm = cbind(cbc.mm[, colnames(cbc.mm) != "choice"], cmr_choice)
cmr.mm.bez.cov = cmr.mm[, !(colnames(cmr.mm) %in% cov.columns)]
demos = NULL
if (length(designctx$covariates) > 0) {
# zbog ponavljanja demografije u redovima, trebamo izvaditi samo 1., 2., ... max(resp.id)
max_resp_id = max(cmr.mm$resp.id)
total_rows = nrow(cmr.mm)
demos = as.matrix(cmr.mm[(0:(max_resp_id-1))*(total_rows/max_resp_id)+1, cov.columns])
}
## Build and save the model
if (!is.null(demos)) {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
demos = demos,
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
} else {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
}
cbc.df2
source("surveyconfig.R")
designctx = readRDS(designctxfile)
cbc.df = read.csv(answersfile, header = TRUE, sep = ",", quote = "\"", stringsAsFactors = FALSE)
simcoefs = NULL
if (file.exists(simulatecoefsfile)) simcoefs = readRDS(simulatecoefsfile)
r = lapply(colnames(designctx$survey), function(cn) {
if (!is.null(cbc.df[[cn]])) {
cbc.df[[cn]] <<- factor(cbc.df[[cn]], levels = levels(designctx$survey[[cn]]))
}
})
r = lapply(colnames(designctx$fullfact_covdesign), function(cn) {
if (!is.null(cbc.df[[cn]])) {
cbc.df[[cn]] <<- factor(cbc.df[[cn]], levels = levels(designctx$fullfact_covdesign[[cn]]))
# ovo dodajemo da izbjegnemo kombinaciju (0, 0) koja radi problem recimo za LCA: softmax(0, 0)
# uvijek daje jednake vjerojatnosti za sve segmente pa ne možemo dobiti ništa osim toga
contrasts(cbc.df[[cn]]) <<- contr.sum
}
})
r = lapply(names(designctx$personals), function(pn) {
if (!is.null(cbc.df[[pn]])) {
if (designctx$personals[[pn]][["tip"]] == "dropdown") {
cbc.df[[pn]] <<- factor(cbc.df[[pn]], levels = designctx$personals[[pn]][["vrijednosti"]])
}
}
})
#if (!is.null(cbc.df$questionnaire.id)) cbc.df$questionnaire.id = NULL # maknemo questionnaire.id jer nam ne treba
print(designctx$items)
cbc.df
cbc.df = na.omit(cbc.df) # ako je bilo nedostajućih podataka, treba maknuti retke koji ne nose informacije, PROVJERITI!
cbc.df$resp.id = as.numeric(factor(cbc.df$resp.id)) # renumeracija resp.id ako je bilo micanja nedostajućih podataka
# petlja za svaki resp.id
# enkodirati pitanja, covariates, best+worst choice
# ako ima, enkodirati anchor pitanja kao choice, dodati na kraj data.framea za resp.id
cbc.mm = data.frame(NULL)
for (resp.id in 1:max(cbc.df$resp.id)) {
# izvuci subframe
cbc.df.sf = cbc.df[cbc.df$resp.id == resp.id, ]
nalts = designctx$nalternatives
if (length(designctx$covariates) > 0) {
covs = getdfcolumns(df = cbc.df.sf, cnames = names(designctx$covariates))
sf.mm = domodelmatrix_itemscovs_bwencode(cbc.df.sf$alt, covs, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = attr(sf.mm, "cov.columns")
} else {
covs = data.frame() # da li je ovo uopće potrebno?
sf.mm = domodelmatrix_itemsonly_bwencode(cbc.df.sf$alt, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = c()
}
cbc.mm.sf = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df.sf$resp.id, nalts),
ques = rep(1:(2*max(cbc.df.sf$ques)), each = nalts),
#alt = cbc.df$alt,
alt = rep(1:nalts, nrow(sf.mm)/nalts),
sf.mm,
choice = bw_encode_data(cbc.df.sf$best_choice, cbc.df.sf$worst_choice, nalts)))
if (designctx$anchors > 0) {
anchorcolnames = getanchorcolnames(designctx$anchors)
anchorcols = cbc.df.sf[, colnames(cbc.df.sf) %in% anchorcolnames]
best_choices = cbc.df[cbc.df$best_choice == 1, ]$alt
worst_choices = cbc.df[cbc.df$worst_choice == 1, ]$alt
anchors = getanchors(designctx$anchors, best_choices, worst_choices)
if (length(designctx$covariates) > 0) {
anch.mm = domodelmatrix_itemscovs(anchors, getdfcolumns(covs[rep(1, length(anchors)), ], cnames = colnames(covs)))
} else {
anch.mm = domodelmatrix_itemsonly(anchors)
}
anch.mm = anch.mm[rep(1:nrow(anch.mm), each = 2), ]
anch.mm[2*(1:(nrow(anch.mm)/2)), items.columns] = 0
anch.choices = rep(t(anchorcols[1, ]), each = 2)
anch.choices[2*(1:(length(anch.choices)/2))-1][anchorcols[1, ] == 2] = 0 # neparni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 1] = 0 # parni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 2] = 1 # parni
anch.mm.sf = data.frame(cbind(resp.id = rep(resp.id, nrow(anch.mm)),
ques = rep(max(cbc.mm.sf$ques+1):(max(cbc.mm.sf$ques)+length(anchors)), each = 2),
alt = rep(1:2, nrow(anch.mm)/2),
anch.mm,
choice = anch.choices))
cbc.mm.sf = rbind(cbc.mm.sf, anch.mm.sf)
}
cbc.mm = rbind(cbc.mm, cbc.mm.sf)
}
rownames(cbc.mm) = c()
if (designctx$anchors == 0) {
# remove the Intercept column - it is essentially contained in the alt column (Intercept is when all predictors are 0 - that leaves only the alt as the predictor)
# when we use anchors, then the threshold option is the 0 option, and we don't need to remove the Intercept created with modelling
cbc.mm = cbc.mm[, -4] # 1st item column is the 4th column (after resp.id, ques and alt)
items.columns = items.columns[-1]
}
# items.columns = items.columns[-1]
#
# cbc.mm = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df$resp.id, nalts),
#                           ques = rep(rep(1:(2*designctx$nquestions), each = nalts), max(cbc.df$resp.id)),
# #                          alt = cbc.df$alt,
#                           alt = rep(1:nalts, nrow(mm)/nalts),
#                           mm,
#                           choice = bw_encode_data(cbc.df$best_choice, cbc.df$worst_choice, nalts)))
#
# helper za neke situacije, npr. za stan.mc
cbc.mm.clear = cbc.mm[, items.columns]
cbc.mm
#############################################################################################################
### >>> MIXED MNL
library(mlogit)
cov.df = data.frame() # ovo spremamo da bismo kasnije mogli raditi predikciju s istim ovim ispitanicima
# here we build fml1, which will be used to create a model and model matrix for mlogit
if (length(designctx$covariates) == 0) {
fmlstring = paste("choice ~ 0 + ", paste(items.columns, collapse = "+")) # all vars have generic coefs
fml1 = as.formula(fmlstring)
} else {
#  ncov.columns = setdiff(colnames(mm), cov.columns)
ncov.columns = items.columns
fmlstring1 = paste("0 +", paste(ncov.columns, collapse = "+")) # all but covariates have generic coefs
fmlstring2 = paste("0 +", paste(cov.columns, collapse = "+")) # covariates will have alternative specific coefs
fmlstring = paste("choice ~", fmlstring1, "|", fmlstring2)
fml1 = mFormula(as.formula(fmlstring)) # ovdje je bitno da bude mFormula tako da se kod model.matrix pozove odgovarajuća funkcija!!! >> TO JE SAMO ZA mlogit, NE ZA choicemodelr!
# fmlstring = paste("choice ~ 0 + ", paste(colnames(mm), collapse = "+")) # all vars have generic coefs
# fml1 = mFormula(as.formula(fmlstring))
# fml1 = as.formula(fmlstring)
repeats = designctx$nquestions * designctx$nalternatives
respondents = max(cbc.df$resp.id)
cov.df = as.data.frame(cbc.df[(0:(respondents-1))*repeats+1, colnames(cbc.df) %in% names(designctx$covariates)])
colnames(cov.df) = names(designctx$covariates)
}
# fml1 = as.formula(paste("choice ~ ", paste(g.columns, collapse = "+"), "| 0 |", paste(ascolumns, collapse = "+")))
# head(model.matrix(fml1, cbc.mlogit), 10)
vars_i = 4:(ncol(cbc.mm)-1) # skip over the first three: resp.id, ques, alt
cbc.mm$resp.ques = paste(cbc.mm$resp.id, ".", cbc.mm$ques, sep = "")
cbc.mlogit = mlogit.data(data = cbc.mm, choice = "choice", shape = "long",
#varying = vars_i,
alt.var = "alt",
#alt.levels = levels(factor(cbc.mm$alt)),
#alt.levels = unique(cbc.mm$alt),
chid.var = "resp.ques",
id.var = "resp.id")
## BUILD AND SAVE MODEL
# Ako imamo covariates, onda model prolazi samo ako se koeficijenti covariates računaju kao alternative specific
# (znači u formuli idu iza | i s 0 +)
m1 = mlogit(fml1, data = cbc.mlogit)
# summary(m1)
m1.rpar = rep("n", length = length(m1$coef)) # 'n' normal, 'l' log-normal, 't' truncated normal, 'u' uniform
names(m1.rpar) = names(m1$coef)
m2.hier = mlogit(fml1, data = cbc.mlogit, panel = TRUE, rpar = m1.rpar, correlation = TRUE)
# summary(m1.hier)
# m2.hier = update(m1.hier, correlation = TRUE)
# summary(m2.hier)
# SAVE/LOAD
m2.hier$cov.df = cov.df
saveRDS(m2.hier, mnlmodelfile)
## LOAD MODEL
if (!is.null(cbc.mm$resp.ques)) cbc.mm$resp.ques = NULL
m2.hier = readRDS(mnlmodelfile)
sm.mnl = summary(m2.hier)$summary.rpar
#############################################################################################################
### >>> HIERARCHICAL BAYES
library(ChoiceModelR)
# # modeliranje
cmr_choice = rep(0, nrow(cbc.mm))
cmr_choice[cbc.mm$alt == 1] = cbc.mm[cbc.mm$choice == 1, "alt"]
cmr.mm = cbind(cbc.mm[, colnames(cbc.mm) != "choice"], cmr_choice)
cmr.mm.bez.cov = cmr.mm[, !(colnames(cmr.mm) %in% cov.columns)]
demos = NULL
if (length(designctx$covariates) > 0) {
# zbog ponavljanja demografije u redovima, trebamo izvaditi samo 1., 2., ... max(resp.id)
max_resp_id = max(cmr.mm$resp.id)
total_rows = nrow(cmr.mm)
demos = as.matrix(cmr.mm[(0:(max_resp_id-1))*(total_rows/max_resp_id)+1, cov.columns])
}
## Build and save the model
if (!is.null(demos)) {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
demos = demos,
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
} else {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
}
saveRDS(hb.post, hbmodelfile)
##
hb.post = readRDS(hbmodelfile)
# names(hb.post)
# betadraw su sva izvlačenja: ni (useri) x natt (atributi) x ndraws (izvlačenja)
# compdraw su sva izvlačenja srednjih vrijednosti atributa i (ko)varijanci: ndraw x (mu: natt, rooti: natt x natt) [bez utjecaja covariates, tj. kad su covariates = 0]
# deltadraw su sva izvlačenja adjustmentsa za covariates: ndraw x (ncovariates x natt)
# adjustments idu ovim redom: 1.cov/1.att, 2.cov/1.att, ..., n.cov/1.att, 1.cov/2.att, 2.cov/2.att...
# itd. sve do 1.cov/n.att, 2.cov/n.att, ... , n.cov/n.att
# u apply MARGIN označava indekse koje fiksiramo, a onda sve ostale indekse zbrojimo/izračunamo prosjek
# npr. ako je a 3x4x5 apply(a, 2:3, mean) će za svaki par iz svih parova 2.-og i 3.-eg indeksa sumirati sve elemente
# za 1. indeks i izračunati sredinu; ukupno će rezultat biti 4x5
# za fiksiranog usera i atribut, izračunaj prosječnu vrijednost izvlačenja, odn. koeficijenta
# delta.means = apply(delta.d, c(1, 3), sum) # draws of total effect from all covariates on attributes
beta.post.mean = apply(hb.post$betadraw, 1:2, mean) # izračun svih prosječnih koeficijenata za svakog ispitanika
sm_means = apply(t(beta.post.mean), 1, mean)
beta.post.q25 = apply(hb.post$betadraw, 1:2, quantile, probs = c(0.25)) # isto kao gore, samo 25% kvantil
beta.post.q75 = apply(hb.post$betadraw, 1:2, quantile, probs = c(0.75)) # isto kao gore, samo 75% kvantil
sm_q25 = apply(t(beta.post.q25), 1, mean)
sm_q75 = apply(t(beta.post.q75), 1, mean)
sm.hb = cbind("1st Qu." = sm_q25, "Mean" = sm_means, "3rd Qu." = sm_q75)
rownames(sm.hb) = setdiff(colnames(cmr.mm.bez.cov), c("resp.id", "ques", "alt", "cmr_choice"))
sm.hb
### HIERARCHICAL BAYES <<<
#############################################################################################################
# petlja za svaki resp.id
# enkodirati pitanja, covariates, best+worst choice
# ako ima, enkodirati anchor pitanja kao choice, dodati na kraj data.framea za resp.id
cbc.mm = data.frame(NULL)
for (resp.id in 1:max(cbc.df$resp.id)) {
# izvuci subframe
cbc.df.sf = cbc.df[cbc.df$resp.id == resp.id, ]
nalts = designctx$nalternatives
if (length(designctx$covariates) > 0) {
covs = getdfcolumns(df = cbc.df.sf, cnames = names(designctx$covariates))
sf.mm = domodelmatrix_itemscovs_bwencode(cbc.df.sf$alt, covs, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = attr(sf.mm, "cov.columns")
} else {
covs = data.frame() # da li je ovo uopće potrebno?
sf.mm = domodelmatrix_itemsonly_bwencode(cbc.df.sf$alt, nalts)
items.columns = attr(sf.mm, "items.columns")
cov.columns = c()
}
cbc.mm.sf = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df.sf$resp.id, nalts),
ques = rep(1:(2*max(cbc.df.sf$ques)), each = nalts),
#alt = cbc.df$alt,
alt = rep(1:nalts, nrow(sf.mm)/nalts),
sf.mm,
choice = bw_encode_data(cbc.df.sf$best_choice, cbc.df.sf$worst_choice, nalts)))
if (designctx$anchors > 0) {
anchorcolnames = getanchorcolnames(designctx$anchors)
anchorcols = cbc.df.sf[, colnames(cbc.df.sf) %in% anchorcolnames]
best_choices = cbc.df.sf[cbc.df.sf$best_choice == 1, ]$alt
worst_choices = cbc.df.sf[cbc.df.sf$worst_choice == 1, ]$alt
anchors = getanchors(designctx$anchors, best_choices, worst_choices)
if (length(designctx$covariates) > 0) {
anch.mm = domodelmatrix_itemscovs(anchors, getdfcolumns(covs[rep(1, length(anchors)), ], cnames = colnames(covs)))
} else {
anch.mm = domodelmatrix_itemsonly(anchors)
}
anch.mm = anch.mm[rep(1:nrow(anch.mm), each = 2), ]
anch.mm[2*(1:(nrow(anch.mm)/2)), items.columns] = 0
anch.choices = rep(t(anchorcols[1, ]), each = 2)
anch.choices[2*(1:(length(anch.choices)/2))-1][anchorcols[1, ] == 2] = 0 # neparni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 1] = 0 # parni
anch.choices[2*(1:(length(anch.choices)/2))][anchorcols[1, ] == 2] = 1 # parni
anch.mm.sf = data.frame(cbind(resp.id = rep(resp.id, nrow(anch.mm)),
ques = rep(max(cbc.mm.sf$ques+1):(max(cbc.mm.sf$ques)+length(anchors)), each = 2),
alt = rep(1:2, nrow(anch.mm)/2),
anch.mm,
choice = anch.choices))
cbc.mm.sf = rbind(cbc.mm.sf, anch.mm.sf)
}
cbc.mm = rbind(cbc.mm, cbc.mm.sf)
}
rownames(cbc.mm) = c()
if (designctx$anchors == 0) {
# remove the Intercept column - it is essentially contained in the alt column (Intercept is when all predictors are 0 - that leaves only the alt as the predictor)
# when we use anchors, then the threshold option is the 0 option, and we don't need to remove the Intercept created with modelling
cbc.mm = cbc.mm[, -4] # 1st item column is the 4th column (after resp.id, ques and alt)
items.columns = items.columns[-1]
}
# items.columns = items.columns[-1]
#
# cbc.mm = data.frame(cbind(resp.id = bw_encode_data_1(cbc.df$resp.id, nalts),
#                           ques = rep(rep(1:(2*designctx$nquestions), each = nalts), max(cbc.df$resp.id)),
# #                          alt = cbc.df$alt,
#                           alt = rep(1:nalts, nrow(mm)/nalts),
#                           mm,
#                           choice = bw_encode_data(cbc.df$best_choice, cbc.df$worst_choice, nalts)))
#
# helper za neke situacije, npr. za stan.mc
cbc.mm.clear = cbc.mm[, items.columns]
#############################################################################################################
### >>> MIXED MNL
library(mlogit)
cov.df = data.frame() # ovo spremamo da bismo kasnije mogli raditi predikciju s istim ovim ispitanicima
# here we build fml1, which will be used to create a model and model matrix for mlogit
if (length(designctx$covariates) == 0) {
fmlstring = paste("choice ~ 0 + ", paste(items.columns, collapse = "+")) # all vars have generic coefs
fml1 = as.formula(fmlstring)
} else {
#  ncov.columns = setdiff(colnames(mm), cov.columns)
ncov.columns = items.columns
fmlstring1 = paste("0 +", paste(ncov.columns, collapse = "+")) # all but covariates have generic coefs
fmlstring2 = paste("0 +", paste(cov.columns, collapse = "+")) # covariates will have alternative specific coefs
fmlstring = paste("choice ~", fmlstring1, "|", fmlstring2)
fml1 = mFormula(as.formula(fmlstring)) # ovdje je bitno da bude mFormula tako da se kod model.matrix pozove odgovarajuća funkcija!!! >> TO JE SAMO ZA mlogit, NE ZA choicemodelr!
# fmlstring = paste("choice ~ 0 + ", paste(colnames(mm), collapse = "+")) # all vars have generic coefs
# fml1 = mFormula(as.formula(fmlstring))
# fml1 = as.formula(fmlstring)
repeats = designctx$nquestions * designctx$nalternatives
respondents = max(cbc.df$resp.id)
cov.df = as.data.frame(cbc.df[(0:(respondents-1))*repeats+1, colnames(cbc.df) %in% names(designctx$covariates)])
colnames(cov.df) = names(designctx$covariates)
}
# fml1 = as.formula(paste("choice ~ ", paste(g.columns, collapse = "+"), "| 0 |", paste(ascolumns, collapse = "+")))
# head(model.matrix(fml1, cbc.mlogit), 10)
vars_i = 4:(ncol(cbc.mm)-1) # skip over the first three: resp.id, ques, alt
cbc.mm$resp.ques = paste(cbc.mm$resp.id, ".", cbc.mm$ques, sep = "")
cbc.mlogit = mlogit.data(data = cbc.mm, choice = "choice", shape = "long",
#varying = vars_i,
alt.var = "alt",
#alt.levels = levels(factor(cbc.mm$alt)),
#alt.levels = unique(cbc.mm$alt),
chid.var = "resp.ques",
id.var = "resp.id")
## BUILD AND SAVE MODEL
# Ako imamo covariates, onda model prolazi samo ako se koeficijenti covariates računaju kao alternative specific
# (znači u formuli idu iza | i s 0 +)
m1 = mlogit(fml1, data = cbc.mlogit)
# summary(m1)
m1.rpar = rep("n", length = length(m1$coef)) # 'n' normal, 'l' log-normal, 't' truncated normal, 'u' uniform
names(m1.rpar) = names(m1$coef)
m2.hier = mlogit(fml1, data = cbc.mlogit, panel = TRUE, rpar = m1.rpar, correlation = TRUE)
# summary(m1.hier)
# m2.hier = update(m1.hier, correlation = TRUE)
# summary(m2.hier)
# SAVE/LOAD
m2.hier$cov.df = cov.df
saveRDS(m2.hier, mnlmodelfile)
## LOAD MODEL
if (!is.null(cbc.mm$resp.ques)) cbc.mm$resp.ques = NULL
m2.hier = readRDS(mnlmodelfile)
sm.mnl = summary(m2.hier)$summary.rpar
#############################################################################################################
### >>> HIERARCHICAL BAYES
library(ChoiceModelR)
# # modeliranje
cmr_choice = rep(0, nrow(cbc.mm))
cmr_choice[cbc.mm$alt == 1] = cbc.mm[cbc.mm$choice == 1, "alt"]
cmr.mm = cbind(cbc.mm[, colnames(cbc.mm) != "choice"], cmr_choice)
cmr.mm.bez.cov = cmr.mm[, !(colnames(cmr.mm) %in% cov.columns)]
demos = NULL
if (length(designctx$covariates) > 0) {
# zbog ponavljanja demografije u redovima, trebamo izvaditi samo 1., 2., ... max(resp.id)
max_resp_id = max(cmr.mm$resp.id)
total_rows = nrow(cmr.mm)
demos = as.matrix(cmr.mm[(0:(max_resp_id-1))*(total_rows/max_resp_id)+1, cov.columns])
}
## Build and save the model
if (!is.null(demos)) {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
demos = demos,
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
} else {
hb.post = choicemodelr(data = cmr.mm.bez.cov,
xcoding = rep(1, ncol(cmr.mm.bez.cov) - 4),
mcmc = list(R = 20000, use = 10000),
options = list(save = TRUE))
}
saveRDS(hb.post, hbmodelfile)
##
hb.post = readRDS(hbmodelfile)
# names(hb.post)
# betadraw su sva izvlačenja: ni (useri) x natt (atributi) x ndraws (izvlačenja)
# compdraw su sva izvlačenja srednjih vrijednosti atributa i (ko)varijanci: ndraw x (mu: natt, rooti: natt x natt) [bez utjecaja covariates, tj. kad su covariates = 0]
# deltadraw su sva izvlačenja adjustmentsa za covariates: ndraw x (ncovariates x natt)
# adjustments idu ovim redom: 1.cov/1.att, 2.cov/1.att, ..., n.cov/1.att, 1.cov/2.att, 2.cov/2.att...
# itd. sve do 1.cov/n.att, 2.cov/n.att, ... , n.cov/n.att
# u apply MARGIN označava indekse koje fiksiramo, a onda sve ostale indekse zbrojimo/izračunamo prosjek
# npr. ako je a 3x4x5 apply(a, 2:3, mean) će za svaki par iz svih parova 2.-og i 3.-eg indeksa sumirati sve elemente
# za 1. indeks i izračunati sredinu; ukupno će rezultat biti 4x5
# za fiksiranog usera i atribut, izračunaj prosječnu vrijednost izvlačenja, odn. koeficijenta
# delta.means = apply(delta.d, c(1, 3), sum) # draws of total effect from all covariates on attributes
beta.post.mean = apply(hb.post$betadraw, 1:2, mean) # izračun svih prosječnih koeficijenata za svakog ispitanika
sm_means = apply(t(beta.post.mean), 1, mean)
beta.post.q25 = apply(hb.post$betadraw, 1:2, quantile, probs = c(0.25)) # isto kao gore, samo 25% kvantil
beta.post.q75 = apply(hb.post$betadraw, 1:2, quantile, probs = c(0.75)) # isto kao gore, samo 75% kvantil
sm_q25 = apply(t(beta.post.q25), 1, mean)
sm_q75 = apply(t(beta.post.q75), 1, mean)
sm.hb = cbind("1st Qu." = sm_q25, "Mean" = sm_means, "3rd Qu." = sm_q75)
rownames(sm.hb) = setdiff(colnames(cmr.mm.bez.cov), c("resp.id", "ques", "alt", "cmr_choice"))
sm.hb
### HIERARCHICAL BAYES <<<
#############################################################################################################
